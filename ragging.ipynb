{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-07T20:08:21.226706Z",
     "start_time": "2025-01-07T20:08:21.222707Z"
    }
   },
   "source": [
    "from haystack_integrations.components.generators.ollama import OllamaGenerator\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.retrievers.in_memory import InMemoryBM25Retriever\n",
    "\n",
    "from haystack import Document,Pipeline\n",
    "from haystack.components.builders.prompt_builder import PromptBuilder\n"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T20:08:21.484053Z",
     "start_time": "2025-01-07T20:08:21.236496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "generator = OllamaGenerator(model=\"llama3.1\",\n",
    "                            url = \"http://localhost:11434\",\n",
    "                            generation_kwargs={\n",
    "                              \"num_predict\": 100,\n",
    "                              \"temperature\": 0.9,\n",
    "                              })\n",
    "\n",
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "document_store.write_documents([Document(content=\"I like fish\"),\n",
    "                               Document(content=\"My favorite color is blue\"),\n",
    "                               Document(content=\"My favorite sport is F1\")])\n",
    "\n",
    "retriever = InMemoryBM25Retriever(document_store=document_store)\n",
    "\n",
    "template = \"\"\"\n",
    "Given the following information, answer the question.\n",
    "Context: \n",
    "{% for document in documents %}\n",
    "\n",
    "    {{ document.content }}\n",
    "\n",
    "{% endfor %}\n",
    "Question: {{ query }}?\n",
    "\"\"\"\n",
    "\n",
    "pipe = Pipeline()\n",
    "\n",
    "pipe.add_component(\"retriever\", retriever)\n",
    "pipe.add_component(\"llm\", generator)\n",
    "pipe.add_component(\"prompt_builder\", PromptBuilder(template=template))\n",
    "pipe.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "pipe.connect(\"prompt_builder\", \"llm\")"
   ],
   "id": "a59b92c2b7fa105e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x0000021AF334DD60>\n",
       "ðŸš… Components\n",
       "  - retriever: InMemoryBM25Retriever\n",
       "  - llm: OllamaGenerator\n",
       "  - prompt_builder: PromptBuilder\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
       "  - prompt_builder.prompt -> llm.prompt (str)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T20:08:24.986494Z",
     "start_time": "2025-01-07T20:08:21.573183Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your favorite sport is Formula 1 (F1).\n"
     ]
    }
   ],
   "execution_count": 20,
   "source": [
    "query = \"What is my favorite sport?\"\n",
    "\n",
    "result = pipe.run({\"prompt_builder\" : {\"query\":query}, \"retriever\" : {\"query\":query}})\n",
    "print(result[\"llm\"][\"replies\"][0])"
   ],
   "id": "3b622ebacc088026"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T22:24:55.815609Z",
     "start_time": "2025-01-07T22:24:55.591019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from haystack.components.preprocessors import DocumentSplitter\n",
    "from pathlib import Path\n",
    "from haystack.components.converters import PyPDFToDocument\n",
    "from haystack.components.preprocessors import DocumentSplitter\n",
    "from haystack.components.preprocessors import DocumentCleaner\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack_integrations.document_stores.chroma import ChromaDocumentStore\n",
    "from haystack_integrations.components.embedders.ollama import OllamaDocumentEmbedder\n",
    "from haystack import Pipeline\n",
    "\n",
    "converter = PyPDFToDocument()\n",
    "splitter = DocumentSplitter(split_by=\"function\", splitting_function=)\n",
    "cleaner = DocumentCleaner()\n",
    "document_store = ChromaDocumentStore(persist_path=\"db\")\n",
    "writer = DocumentWriter(document_store=document_store)\n",
    "\n",
    "embedder = OllamaDocumentEmbedder()\n",
    "\n",
    "document_encoder = Pipeline()\n",
    "document_encoder.add_component(\"converter\", converter)\n",
    "document_encoder.add_component(\"cleaner\", cleaner)\n",
    "document_encoder.add_component(\"splitter\", splitter)\n",
    "document_encoder.add_component(\"embedder\", embedder)\n",
    "document_encoder.add_component(\"writer\", writer)\n",
    "\n",
    "document_encoder.connect(\"converter\", \"cleaner\")\n",
    "document_encoder.connect(\"cleaner\", \"splitter\")\n",
    "document_encoder.connect(\"splitter\", \"embedder\")\n",
    "document_encoder.connect(\"embedder\", \"writer\")"
   ],
   "id": "5a41d0955c733f6e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x000002318084F830>\n",
       "ðŸš… Components\n",
       "  - converter: PyPDFToDocument\n",
       "  - cleaner: DocumentCleaner\n",
       "  - splitter: DocumentSplitter\n",
       "  - embedder: OllamaDocumentEmbedder\n",
       "  - writer: DocumentWriter\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - converter.documents -> cleaner.documents (List[Document])\n",
       "  - cleaner.documents -> splitter.documents (List[Document])\n",
       "  - splitter.documents -> embedder.documents (List[Document])\n",
       "  - embedder.documents -> writer.documents (List[Document])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T22:25:02.743229Z",
     "start_time": "2025-01-07T22:24:56.552891Z"
    }
   },
   "cell_type": "code",
   "source": "document_encoder.run({\"converter\" : {\"sources\" : [Path(\"FS-Rules_2025_v1.0.pdf\")]}})",
   "id": "8b5c8014515313b8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.16s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'embedder': {'meta': {'model': 'nomic-embed-text'}},\n",
       " 'writer': {'documents_written': 23}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Create document with the short things\n",
    "# Prep the regs\n",
    "# Split at subsections?"
   ],
   "id": "870a8821ebdc5704"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e00cf95ed5010eb9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
