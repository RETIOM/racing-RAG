{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import umap\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from typing import List, Optional\n",
    "\n",
    "\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "RANDOM_SEED = 224\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "def global_cluster_embeddings(\n",
    "    embeddings: np.ndarray,\n",
    "    dim: int,\n",
    "    n_neighbors: Optional[int] = None,\n",
    "    metric: str = \"cosine\",\n",
    ") -> np.ndarray:\n",
    "    if n_neighbors is None:\n",
    "        n_neighbors = int((len(embeddings) - 1) ** 0.5)\n",
    "    return umap.UMAP(\n",
    "        n_neighbors=n_neighbors, n_components=dim, metric=metric\n",
    "    ).fit_transform(embeddings)\n",
    "\n",
    "\n",
    "def local_cluster_embeddings(\n",
    "    embeddings: np.ndarray, dim: int, num_neighbors: int = 10, metric: str = \"cosine\"\n",
    ") -> np.ndarray:\n",
    "    return umap.UMAP(\n",
    "        n_neighbors=num_neighbors, n_components=dim, metric=metric\n",
    "    ).fit_transform(embeddings)\n",
    "\n",
    "\n",
    "def get_optimal_clusters(\n",
    "    embeddings: np.ndarray, max_clusters: int = 50, random_state: int = RANDOM_SEED\n",
    ") -> int:\n",
    "    max_clusters = min(max_clusters, len(embeddings))\n",
    "    n_clusters = np.arange(1, max_clusters)\n",
    "    bics = []\n",
    "    for n in n_clusters:\n",
    "        gm = GaussianMixture(n_components=n, random_state=random_state)\n",
    "        gm.fit(embeddings)\n",
    "        bics.append(gm.bic(embeddings))\n",
    "    return n_clusters[np.argmin(bics)]\n",
    "\n",
    "\n",
    "def GMM_cluster(embeddings: np.ndarray, threshold: float, random_state: int = 0):\n",
    "    n_clusters = get_optimal_clusters(embeddings)\n",
    "    gm = GaussianMixture(n_components=n_clusters, random_state=random_state)\n",
    "    gm.fit(embeddings)\n",
    "    probs = gm.predict_proba(embeddings)\n",
    "    labels = [np.where(prob > threshold)[0] for prob in probs]\n",
    "    return labels, n_clusters\n",
    "\n",
    "\n",
    "def perform_clustering(\n",
    "    embeddings: np.ndarray,\n",
    "    dim: int,\n",
    "    threshold: float,\n",
    ") -> List[np.ndarray]:\n",
    "    # If the number of embeddings is less than or equal to the dimension, return a list of zeros\n",
    "    # This means all nodes are in the same cluster.\n",
    "    # Otherwise, we will get an error when trying to cluster.\n",
    "    if len(embeddings) <= dim + 1:\n",
    "        return [np.array([0]) for _ in range(len(embeddings))]\n",
    "\n",
    "    reduced_embeddings_global = global_cluster_embeddings(embeddings, dim)\n",
    "    global_clusters, n_global_clusters = GMM_cluster(\n",
    "        reduced_embeddings_global, threshold\n",
    "    )\n",
    "\n",
    "    all_local_clusters = [np.array([]) for _ in range(len(embeddings))]\n",
    "    total_clusters = 0\n",
    "\n",
    "    for i in range(n_global_clusters):\n",
    "        global_cluster_embeddings_ = embeddings[\n",
    "            np.array([i in gc for gc in global_clusters])\n",
    "        ]\n",
    "\n",
    "        if len(global_cluster_embeddings_) == 0:\n",
    "            continue\n",
    "        if len(global_cluster_embeddings_) <= dim + 1:\n",
    "            local_clusters = [np.array([0]) for _ in global_cluster_embeddings_]\n",
    "            n_local_clusters = 1\n",
    "        else:\n",
    "            reduced_embeddings_local = local_cluster_embeddings(\n",
    "                global_cluster_embeddings_, dim\n",
    "            )\n",
    "            local_clusters, n_local_clusters = GMM_cluster(\n",
    "                reduced_embeddings_local, threshold\n",
    "            )\n",
    "\n",
    "        for j in range(n_local_clusters):\n",
    "            local_cluster_embeddings_ = global_cluster_embeddings_[\n",
    "                np.array([j in lc for lc in local_clusters])\n",
    "            ]\n",
    "            indices = np.where(\n",
    "                (embeddings == local_cluster_embeddings_[:, None]).all(-1)\n",
    "            )[1]\n",
    "            for idx in indices:\n",
    "                all_local_clusters[idx] = np.append(\n",
    "                    all_local_clusters[idx], j + total_clusters\n",
    "                )\n",
    "\n",
    "        total_clusters += n_local_clusters\n",
    "\n",
    "    return all_local_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0886d2fcf13d71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings from existing rule store; TODO find a way to split and batch embed all\n",
    "\n",
    "from ingest import Node\n",
    "import pickle\n",
    "\n",
    "f = open('data/rules.dat', 'rb')\n",
    "f.seek(0)\n",
    "tree = pickle.load(f)\n",
    "root = tree[0]\n",
    "\n",
    "def get_leaf_node_embeddings(current_node: Node, leaves: list[float]) -> None:\n",
    "    if len(current_node.children)==0:\n",
    "        leaves.append(current_node.vec)\n",
    "        return\n",
    "\n",
    "    for child in current_node.children:\n",
    "        get_leaf_node_embeddings(child,leaves)\n",
    "\n",
    "leaves = []\n",
    "leaves = get_leaf_node_embeddings(root, leaves)\n",
    "\n",
    "# clusters = perform_clustering(\n",
    "#     embeddings=leaves,\n",
    "#     dim=10,\n",
    "#     threshold=0.1\n",
    "# )\n",
    "\n",
    "# clusters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a6fc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ingest import embed_summarize\n",
    "\n",
    "def join_content(content: list[str]) -> str:\n",
    "    return \"----- \\n -----\".join(content)\n",
    "\n",
    "def create_node(child_nodes: list[Node]) -> Node:\n",
    "    text = [node.content for node in child_nodes]\n",
    "    \n",
    "    summary, embedding = embed_summarize(join_content(text), True)\n",
    "    \n",
    "    return Node(summary, embedding, child_nodes)\n",
    "\n",
    "def create_tree(buckets: list[Node], num_layers: int, max_layers: int) -> Node:\n",
    "    if num_layers == max_layers:\n",
    "        return Node(children=buckets)\n",
    "    elif len(buckets) == 1:\n",
    "        return buckets[0]\n",
    "    \n",
    "    embeddings = [node.vec for node in buckets]\n",
    "    \n",
    "    cluster_list = perform_clustering(\n",
    "        embeddings = embeddings,\n",
    "        dim = 10,\n",
    "        threshold = 0.1\n",
    "    )\n",
    "    \n",
    "    clusters = dict()\n",
    "    \n",
    "    for id, node in enumerate(buckets):\n",
    "        for bucket in cluster_list[id]:\n",
    "            try: \n",
    "                clusters[bucket].append(node)\n",
    "            except KeyError:\n",
    "                clusters[bucket] = [node]\n",
    "                \n",
    "    print(f\"Generated {len(clusters.keys)} clusters\")\n",
    "    \n",
    "    buckets = [create_node(children) for children in clusters.values]\n",
    "    num_layers += 1\n",
    "    \n",
    "    create_tree(buckets, num_layers, max_layers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
